{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11367955,"sourceType":"datasetVersion","datasetId":7116033}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport math\nimport torch\nimport torch.nn as nn\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\nfrom tqdm.notebook import tqdm\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.cuda.amp import GradScaler, autocast\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# Reproducibility\ndef seed_everything(seed=42):\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    np.random.seed(seed)\n\nseed_everything()\n\n# Timestamp parser\ndef parse_timestamp(timestamp_str):\n    if pd.isna(timestamp_str):\n        return 0\n    try:\n        parts = timestamp_str.split(':')\n        if len(parts) == 2:\n            h, m = map(int, parts)\n            return h * 60 + m\n        elif len(parts) == 3:\n            h, m, s = map(int, parts)\n            return h * 60 + m + s / 60\n    except:\n        return 0\n    return 0\n\n# Dataset\nenabled_meta = ['timestamp', 'latitude', 'longitude', 'Region_ID', 'filename', 'angle']\nclass MultimodalAngleDataset(Dataset):\n    def __init__(self, df, img_dir, region_encoder, transform=None):\n        self.df = df.copy().reset_index(drop=True)\n        self.img_dir = img_dir\n        self.transform = transform\n        self.region_encoder = region_encoder\n\n        # parse and fill\n        self.df['time_minutes'] = self.df['timestamp'].apply(parse_timestamp)\n        for c in ['latitude', 'longitude', 'time_minutes']:\n            self.df[c].fillna(self.df[c].median(), inplace=True)\n        self.df['region_idx'] = self.region_encoder.transform(self.df['Region_ID'])\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img = Image.open(os.path.join(self.img_dir, row['filename'])).convert('RGB')\n        if self.transform:\n            img = self.transform(img)\n\n        # angle target\n        angle = float(row['angle'])\n        sin_a = math.sin(math.radians(angle))\n        cos_a = math.cos(math.radians(angle))\n        target = torch.tensor([cos_a, sin_a], dtype=torch.float32)\n\n        # meta features\n        t = row['time_minutes'] / (24*60) * 2 * math.pi\n        ts, tc = math.sin(t), math.cos(t)\n        lat_rad = row['latitude'] / 180 * math.pi\n        ls, lc = math.sin(lat_rad), math.cos(lat_rad)\n        lon_rad = row['longitude'] / 360 * 2 * math.pi\n        los, loc = math.sin(lon_rad), math.cos(lon_rad)\n        meta = torch.tensor([ts, tc, ls, lc, los, loc], dtype=torch.float32)\n\n        region_idx = torch.tensor(row['region_idx'], dtype=torch.long)\n        return img, meta, region_idx, target\n\n# Transforms (must be multiple of 14)\ntrain_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ColorJitter(0.1, 0.1),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\nval_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n# Load data\nroot = \"/kaggle/input/smainewdataset/Phase_2_data\"\ntrain_df = pd.read_csv(os.path.join(root, \"labels_train.csv\"))\nval_df   = pd.read_csv(os.path.join(root, \"labels_val.csv\"))\ntrain_img_dir = os.path.join(root, \"images_train/images_train\")\nval_img_dir   = os.path.join(root, \"images_val/images_val\")\n\n# Region encoder\nregion_encoder = LabelEncoder()\nregion_encoder.fit(pd.concat([train_df['Region_ID'], val_df['Region_ID']]))\nnum_regions = len(region_encoder.classes_)\n\n# DataLoaders\ntrain_ds = MultimodalAngleDataset(train_df, train_img_dir, region_encoder, train_transform)\nval_ds   = MultimodalAngleDataset(val_df,   val_img_dir,   region_encoder, val_transform)\ntrain_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4, pin_memory=True)\nval_loader   = DataLoader(val_ds,   batch_size=4, shuffle=False, num_workers=4, pin_memory=True)\n\n# Model definition\nclass DinoV2AngleRegressor(nn.Module):\n    def __init__(self, num_regions, region_emb_dim=16):\n        super().__init__()\n        # load DINOv2 ViT-B/14\n        self.backbone = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitb14', pretrained=True)\n        embed_dim = self.backbone.embed_dim  # 768\n        # freeze patch and first half blocks\n        for name, module in self.backbone.named_children():\n            if name == 'patch_embed':\n                for p in module.parameters(): p.requires_grad=False\n            if name == 'blocks':\n                for i, blk in enumerate(module):\n                    if i < 6:\n                        for p in blk.parameters(): p.requires_grad=False\n        # region embedding and meta encoder\n        self.region_emb = nn.Embedding(num_regions, region_emb_dim)\n        self.meta_enc = nn.Sequential(\n            nn.Linear(6 + region_emb_dim, 64), nn.ReLU(),\n            nn.Linear(64, 128), nn.ReLU()\n        )\n        # head\n        self.head = nn.Sequential(\n            nn.Linear(embed_dim + 128, 384), nn.ReLU(), nn.Dropout(0.1),\n            nn.Linear(384, 2)\n        )\n\n    def forward(self, x_img, x_meta, region_idx):\n        feats = self.backbone.forward_features(x_img)\n        # unwrap dict if needed\n        if isinstance(feats, dict):\n            feats = feats.get('x', feats.get('x_norm', next(iter(feats.values()))))\n        r = self.region_emb(region_idx)\n        meta = self.meta_enc(torch.cat([x_meta, r], dim=1))\n        raw = self.head(torch.cat([feats, meta], dim=1))\n        norm = raw.norm(dim=1, keepdim=True).clamp(min=1e-6)\n        return raw / norm\n\n# Loss and metric\ndef angle_mae(pred, target):\n    dots = (pred * target).sum(dim=1).clamp(-1, 1)\n    return (torch.acos(dots) * 180 / math.pi).mean().item()\ncriterion = nn.MSELoss()\n\n# Training function\n\ndef train_model(model, train_loader, val_loader,\n                epochs=300, acc_steps=2,\n                lr_backbone=5e-6, lr_head=5e-4,\n                weight_decay=1e-2, min_lr=1e-7):\n    model.to(device)\n    # parameter groups\n    backbone_params = [p for _, p in model.backbone.named_parameters() if p.requires_grad]\n    head_params = list(model.head.parameters()) + \\\n                  list(model.region_emb.parameters()) + \\\n                  list(model.meta_enc.parameters())\n    optimizer = torch.optim.AdamW([\n        {'params': backbone_params, 'lr': lr_backbone},\n        {'params': head_params,     'lr': lr_head}\n    ], weight_decay=weight_decay)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=min_lr)\n    scaler = GradScaler()\n\n    best_mae = float('inf')\n    preds_dir = \"angle_predictions\"\n    os.makedirs(preds_dir, exist_ok=True)\n\n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        optimizer.zero_grad()\n        for i, (imgs, metas, regions, targets) in enumerate(tqdm(train_loader, desc=f\"Train {epoch+1}/{epochs}\")):\n            imgs, metas, regions, targets = imgs.to(device), metas.to(device), regions.to(device), targets.to(device)\n            with autocast():\n                preds = model(imgs, metas, regions)\n                loss = criterion(preds, targets) / acc_steps\n            scaler.scale(loss).backward()\n            running_loss += loss.item() * imgs.size(0) * acc_steps\n            if (i + 1) % acc_steps == 0:\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad()\n        scheduler.step()\n        train_loss = running_loss / len(train_loader.dataset)\n\n        # Validation\n        model.eval()\n        all_p, all_t = [], []\n        with torch.no_grad():\n            for imgs, metas, regions, targets in tqdm(val_loader, desc=\"Validate\"):\n                imgs, metas, regions, targets = imgs.to(device), metas.to(device), regions.to(device), targets.to(device)\n                p = model(imgs, metas, regions)\n                all_p.append(p)\n                all_t.append(targets)\n        all_p = torch.cat(all_p)\n        all_t = torch.cat(all_t)\n\n        val_mae = angle_mae(all_p, all_t)\n        print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Val MAE={val_mae:.4f}\")\n\n        if val_mae < best_mae:\n            best_mae = val_mae\n            # save model\n            model_path = f\"best_dinov2_regressor_{best_mae:.4f}.pth\"\n            torch.save(model.state_dict(), model_path)\n            # save predictions\n            df_preds = pd.DataFrame({\n                'filename': val_ds.df['filename'],\n                'true_cos': all_t[:,0].cpu().numpy(),\n                'true_sin': all_t[:,1].cpu().numpy(),\n                'pred_cos': all_p[:,0].cpu().numpy(),\n                'pred_sin': all_p[:,1].cpu().numpy(),\n                'angle_true': np.degrees(np.arctan2(all_t[:,1].cpu(), all_t[:,0].cpu())),\n                'angle_pred': np.degrees(np.arctan2(all_p[:,1].cpu(), all_p[:,0].cpu())),\n                'error': np.abs((np.degrees(np.arctan2(all_t[:,1].cpu(), all_t[:,0].cpu())) - \n                                 np.degrees(np.arctan2(all_p[:,1].cpu(), all_p[:,0].cpu())) + 180) % 360 - 180)\n            })\n            csv_path = os.path.join(preds_dir, f\"best_preds_{best_mae:.4f}.csv\")\n            df_preds.to_csv(csv_path, index=False)\n\n    print(f\"Best Val MAE: {best_mae:.4f}\")\n    model.load_state_dict(torch.load(model_path))\n    return model\n\n# Main run\nif __name__ == '__main__':\n    model = DinoV2AngleRegressor(num_regions=num_regions)\n    trained_model = train_model(model, train_loader, val_loader)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-03T22:22:31.696581Z","iopub.execute_input":"2025-05-03T22:22:31.696793Z","iopub.status.idle":"2025-05-03T22:22:31.707002Z","shell.execute_reply.started":"2025-05-03T22:22:31.696776Z","shell.execute_reply":"2025-05-03T22:22:31.706186Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torchvision.models as models\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# ---------- 1. Device ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# ---------- 2. Dataset ----------\nclass RegionDataset(Dataset):\n    def __init__(self, dataframe, img_dir, transform=None):\n        self.df = dataframe\n        self.img_dir = img_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img = Image.open(os.path.join(self.img_dir, row['filename'])).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n        label = int(row['Region_ID']) - 1\n        return img, label\n\n# ---------- 3. Transforms ----------\nval_transform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n\n# ---------- 4. Load Validation Data ----------\nval_csv    = \"/kaggle/input/smainewdataset/Phase_2_data/labels_val.csv\"\nval_img_dir= \"/kaggle/input/smainewdataset/Phase_2_data/images_val/images_val\"\nval_df     = pd.read_csv(val_csv)\nval_df['Region_ID'] = val_df['Region_ID'].astype(int)\n\nval_dataset = RegionDataset(val_df, val_img_dir, transform=val_transform)\nval_loader  = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n\n# ---------- 5. Model Builder ----------\ndef build_model(name='convnext_tiny', num_classes=15, pretrained=False):\n    if name == 'convnext_tiny':\n        m = models.convnext_tiny(pretrained=pretrained)\n        in_feats = m.classifier[2].in_features\n        m.classifier[2] = nn.Linear(in_feats, num_classes)\n    elif name == 'efficientnet_b0':\n        m = models.efficientnet_b0(pretrained=pretrained)\n        in_feats = m.classifier[1].in_features\n        m.classifier[1] = nn.Linear(in_feats, num_classes)\n    elif name == 'resnet50':\n        m = models.resnet50(pretrained=pretrained)\n        in_feats = m.fc.in_features\n        m.fc = nn.Linear(in_feats, num_classes)\n    elif name == 'mobilenet_v3_large':\n        m = models.mobilenet_v3_large(pretrained=pretrained)\n        in_feats = m.classifier[3].in_features\n        m.classifier[3] = nn.Linear(in_feats, num_classes)\n    else:\n        raise ValueError(f\"Unknown model: {name}\")\n    return m\n\n# ---------- 6. Load Checkpoint ----------\nmodel_name      = 'convnext_tiny'\ncheckpoint_path = \"/kaggle/input/region-predict-97.83/tensorflow2/default/1/region_pred_97_83.pth\"\n\nmodel = build_model(name=model_name, num_classes=15, pretrained=False)\nstate = torch.load(checkpoint_path, map_location=device)\nmodel.load_state_dict(state)\nmodel.to(device)\nmodel.eval()\n\n# ---------- 7. Inference + Metrics ----------\nall_preds  = []\nall_labels = []\n\nwith torch.no_grad():\n    for imgs, labels in val_loader:\n        imgs = imgs.to(device)\n        outputs = model(imgs)\n        preds = outputs.argmax(dim=1).cpu().numpy()\n        all_preds.extend(preds)\n        all_labels.extend(labels.numpy())\n\n# 8. Print results\nacc = accuracy_score(all_labels, all_preds)\nprint(f\"Validation Accuracy: {acc:.4f}\\n\")\n\nprint(\"Classification Report:\")\nprint(classification_report(all_labels, all_preds,\n      target_names=[f\"Region_{i+1}\" for i in range(15)]))\n\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(all_labels, all_preds))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T22:22:31.815500Z","iopub.execute_input":"2025-05-03T22:22:31.816347Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n","output_type":"stream"},{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/facebookresearch_dinov2_main\n/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n  warnings.warn(\"xFormers is not available (SwiGLU)\")\n/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n  warnings.warn(\"xFormers is not available (Attention)\")\n/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n  warnings.warn(\"xFormers is not available (Block)\")\n/tmp/ipykernel_1128/1601359001.py:155: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1/30:   0%|          | 0/3271 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4afb2671f0ad46018b0ef3174e33c340"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_1128/1601359001.py:164: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/185 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b14433b8f7ba4c5d99cae5c3a25fa27b"}},"metadata":{}},{"name":"stdout","text":"Epoch 1: Train Loss=0.7810, Val MAE=52.9516\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2/30:   0%|          | 0/3271 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df64d009f30546acaa765d9237f98655"}},"metadata":{}}],"execution_count":null}]}