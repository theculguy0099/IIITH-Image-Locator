{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11367955,"sourceType":"datasetVersion","datasetId":7116033},{"sourceId":347770,"sourceType":"modelInstanceVersion","modelInstanceId":290434,"modelId":311155}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torchvision.models as models\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom torch.optim.lr_scheduler import OneCycleLR\nfrom sklearn.preprocessing import StandardScaler\nimport math\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# Reproducibility\ndef seed_everything(seed=42):\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    np.random.seed(seed)\n\nseed_everything()\n\n# Timestamp parser\ndef parse_timestamp(timestamp_str):\n    if pd.isna(timestamp_str):\n        return 0\n    try:\n        parts = timestamp_str.split(':')\n        if len(parts) == 2:\n            h, m = map(int, parts)\n            return h*60 + m\n        elif len(parts) == 3:\n            h, m, s = map(int, parts)\n            return h*60 + m + s/60\n        else:\n            return 0\n    except:\n        return 0\n\nclass MultimodalAngleDataset(Dataset):\n    def __init__(self, df, img_dir, transform=None):\n        self.df = df.copy().reset_index(drop=True)\n        self.img_dir = img_dir\n        self.transform = transform\n\n        # parse timestamps\n        self.df['time_minutes'] = self.df['timestamp'].apply(parse_timestamp)\n\n        # fill and scale numeric\n        num_feats = ['latitude','longitude','time_minutes']\n        self.scaler = StandardScaler()\n        for c in num_feats:\n            if self.df[c].isna().any():\n                self.df[c].fillna(self.df[c].median(), inplace=True)\n        self.df[num_feats] = self.scaler.fit_transform(self.df[num_feats])\n\n        # region IDs (unused embedding here, but kept as numeric)\n        self.df['Region_ID'] = self.df['Region_ID'].astype(float)\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_path = os.path.join(self.img_dir, row['filename'])\n        img = Image.open(img_path).convert('RGB')\n        if self.transform:\n            img = self.transform(img)\n        angle = float(row['angle'])\n        sin_a = math.sin(math.radians(angle))\n        cos_a = math.cos(math.radians(angle))\n        meta = torch.tensor([\n            row['time_minutes'], row['latitude'], row['longitude'], row['Region_ID']\n        ], dtype=torch.float32)\n        return img, meta, torch.tensor([sin_a, cos_a], dtype=torch.float32), angle, row['filename']\n\n# Transforms\ntrain_transform = transforms.Compose([\n    transforms.Resize((256,256)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(0.1,0.1),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n])\nval_transform = transforms.Compose([\n    transforms.Resize((256,256)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n])\n\n# Load train and validation data\ntrain_csv = \"/kaggle/input/smainewdataset/Phase_2_data/labels_train.csv\"\nval_csv   = \"/kaggle/input/smainewdataset/Phase_2_data/labels_val.csv\"\ntrain_img_dir = \"/kaggle/input/smainewdataset/Phase_2_data/images_train/images_train\"\nval_img_dir   = \"/kaggle/input/smainewdataset/Phase_2_data/images_val/images_val\"\n\ntrain_df = pd.read_csv(train_csv)\nval_df   = pd.read_csv(val_csv)\n\n# Model definition\nclass MultimodalAnglePredictor(nn.Module):\n    def __init__(self, backbone='convnext_tiny', metadata_dim=4):\n        super().__init__()\n        if backbone=='resnet34':\n            base = models.resnet34(pretrained=True)\n            feat_dim = base.fc.in_features\n            self.img_enc = nn.Sequential(*list(base.children())[:-1])\n        elif backbone=='efficientnet_b0':\n            base = models.efficientnet_b0(pretrained=True)\n            feat_dim = base.classifier[1].in_features\n            self.img_enc = nn.Sequential(*list(base.children())[:-1])\n        elif backbone=='convnext_tiny':\n            base = models.convnext_tiny(pretrained=True)\n            feat_dim = base.classifier[2].in_features\n            self.img_enc = nn.Sequential(*list(base.children())[:-1])\n        else:\n            raise ValueError(backbone)\n        self.meta_enc = nn.Sequential(\n            nn.Linear(metadata_dim,64), nn.ReLU(),\n            nn.Linear(64,128), nn.ReLU()\n        )\n        self.head = nn.Sequential(\n            nn.Linear(feat_dim+128,256), nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256,2)\n        )\n    def forward(self, x_img, x_meta):\n        f_img = self.img_enc(x_img).flatten(1)\n        f_meta = self.meta_enc(x_meta)\n        return self.head(torch.cat([f_img,f_meta], dim=1))\n\n# Region Predictor Model\nclass RegionPredictor:\n    def __init__(self, model_path):\n        self.model_path = model_path\n        self.model = MultimodalAnglePredictor(backbone='efficientnet_b0')  # Assuming similar architecture\n        self.model.load_state_dict(torch.load(model_path))\n        self.model.to(device)\n        self.model.eval()\n    \n    def predict(self, img, meta):\n        with torch.no_grad():\n            output = self.model(img, meta)\n            # Assuming output structure is compatible with region prediction\n            # Adjust as necessary based on the actual structure\n            return torch.argmax(output, dim=1)\n\n# Loss and metrics\ndef sin_cos_to_angle(sin_vals, cos_vals):\n    ang = np.degrees(np.arctan2(sin_vals, cos_vals))\n    return (ang + 360) % 360\n\ndef circular_distance(a, b):\n    d = np.abs(a-b)\n    return np.minimum(d, 360-d)\n\ndef circular_mae(a, b):\n    return np.mean(circular_distance(a, b))\n\nclass CircularMSELoss(nn.Module):\n    def forward(self, out, tgt):\n        return ((out - tgt)**2).mean()\n\nclass CircularMAELoss(nn.Module):\n    def forward(self, out, tgt):\n        # Convert sin/cos to angles\n        pred_angles = torch.atan2(out[:, 0], out[:, 1]) * 180 / math.pi\n        pred_angles = (pred_angles + 360) % 360\n        \n        true_angles = torch.atan2(tgt[:, 0], tgt[:, 1]) * 180 / math.pi\n        true_angles = (true_angles + 360) % 360\n        \n        # Calculate circular distance\n        diff = torch.abs(pred_angles - true_angles)\n        circular_diff = torch.min(diff, 360 - diff)\n        \n        return circular_diff.mean()\n\n# Extract image ID from filename\ndef extract_image_id(filename):\n    # Assuming filename format like \"image_123.jpg\"\n    # Extract just the numeric part as the ID\n    return int(os.path.splitext(filename)[0].split('_')[-1])\n\n# Create datasets (without creating loaders yet - we'll create region-specific loaders)\ntrain_ds = MultimodalAngleDataset(train_df, train_img_dir, train_transform)\nval_ds = MultimodalAngleDataset(val_df, val_img_dir, val_transform)\n\n# Get all unique region IDs\nall_region_ids = sorted(train_df['Region_ID'].unique())\nprint(f\"Found {len(all_region_ids)} unique regions: {all_region_ids}\")\n\n# Create region-specific datasets\ndef get_region_indices(dataset, region_id):\n    \"\"\"Get indices of samples belonging to specified region_id\"\"\"\n    indices = []\n    for i in range(len(dataset)):\n        if dataset.df.iloc[i]['Region_ID'] == region_id:\n            indices.append(i)\n    return indices\n\n# # Function to train a single region model\n# def train_region_model(region_id, train_ds, val_ds, backbone='efficientnet_b0', epochs=100, patience=100):\n#     print(f\"\\n{'='*50}\")\n#     print(f\"Training model for Region {region_id}\")\n#     print(f\"{'='*50}\")\n    \n#     # Get indices for this region\n#     train_indices = get_region_indices(train_ds, region_id)\n#     val_indices = get_region_indices(val_ds, region_id)\n    \n#     print(f\"Region {region_id} has {len(train_indices)} training samples and {len(val_indices)} validation samples\")\n    \n#     if len(train_indices) == 0 or len(val_indices) == 0:\n#         print(f\"Skipping Region {region_id} due to insufficient data\")\n#         return None, float('inf'), None\n    \n#     # Create region-specific datasets\n#     region_train_ds = Subset(train_ds, train_indices)\n#     region_val_ds = Subset(val_ds, val_indices)\n    \n#     # Create data loaders\n#     batch_size = min(64, len(region_train_ds))  # Adjust batch size based on dataset size\n#     train_loader = DataLoader(region_train_ds, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n#     val_loader = DataLoader(region_val_ds, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n    \n#     # Initialize model\n#     model = MultimodalAnglePredictor(backbone=backbone)\n#     model.to(device)\n    \n#     # Initialize optimizer, scheduler, and criterion\n#     opt = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.01)\n#     sched = OneCycleLR(opt, max_lr=1e-3, epochs=epochs, steps_per_epoch=len(train_loader))\n#     crit = CircularMSELoss()\n#     mae_crit = CircularMAELoss()  # For monitoring MAE directly\n    \n#     # Training loop with early stopping\n#     best_mae = float('inf')\n#     best_predictions = None\n#     no_improve = 0\n#     out_dir = f\"region_{region_id}_models\"\n#     os.makedirs(out_dir, exist_ok=True)\n    \n#     for ep in range(epochs):\n#         # Training\n#         model.train()\n#         running_loss = 0.0\n#         running_mae = 0.0\n#         for imgs, metas, sincos, angles, _ in tqdm(train_loader, desc=f\"Train Epoch {ep+1}/{epochs}\"):\n#             imgs, metas, sincos = imgs.to(device), metas.to(device), sincos.to(device)\n            \n#             opt.zero_grad()\n#             out = model(imgs, metas)\n            \n#             # Calculate losses\n#             loss = crit(out, sincos)\n#             mae_loss = mae_crit(out, sincos)\n            \n#             # Update model\n#             loss.backward()\n#             opt.step()\n#             sched.step()\n            \n#             # Track metrics\n#             running_loss += loss.item() * imgs.size(0)\n#             running_mae += mae_loss.item() * imgs.size(0)\n            \n#         train_loss = running_loss / len(region_train_ds)\n#         train_mae = running_mae / len(region_train_ds)\n        \n#         # Validation\n#         model.eval()\n#         running_loss = 0.0\n#         true_ang, pred_ang = [], []\n#         img_ids, predictions = [], []\n        \n#         with torch.no_grad():\n#             for imgs, metas, sincos, orig_ang, filenames in tqdm(val_loader, desc=f\"Val Epoch {ep+1}/{epochs}\"):\n#                 imgs, metas = imgs.to(device), metas.to(device)\n#                 sincos = sincos.to(device)\n                \n#                 out = model(imgs, metas)\n#                 loss = crit(out, sincos)\n#                 running_loss += loss.item() * imgs.size(0)\n                \n#                 # Convert to angles for MAE calculation\n#                 ps = out[:, 0].cpu().numpy()\n#                 pc = out[:, 1].cpu().numpy()\n#                 pa = sin_cos_to_angle(ps, pc)\n                \n#                 # Store predictions\n#                 for i in range(len(imgs)):\n#                     img_id = extract_image_id(filenames[i])\n#                     img_ids.append(img_id)\n#                     predictions.append(pa[i])\n                \n#                 true_ang.extend(orig_ang.numpy())\n#                 pred_ang.extend(pa)\n        \n#         # Calculate metrics\n#         val_loss = running_loss / len(region_val_ds)\n#         val_mae = circular_mae(np.array(true_ang), np.array(pred_ang))\n#         val_score = 1.0 / (1.0 + val_mae)\n        \n#         print(f\"Epoch {ep+1}: Train Loss={train_loss:.4f}, Train MAE={train_mae:.4f}, Val Loss={val_loss:.4f}, Val MAE={val_mae:.4f}, Score={val_score:.4f}\")\n        \n#         # Save best model and predictions\n#         if val_mae < best_mae:\n#             best_mae = val_mae\n#             no_improve = 0\n#             # Save model\n#             torch.save(model.state_dict(), os.path.join(out_dir, f\"best_model_region_{region_id}.pth\"))\n            \n#             # Save predictions\n#             best_predictions = pd.DataFrame({\n#                 'id': img_ids,\n#                 'angle': predictions\n#             })\n#             best_predictions.to_csv(os.path.join(out_dir, f\"best_predictions_region_{region_id}.csv\"), index=False)\n#             print(f\"Saved new best model with MAE={best_mae:.4f} and predictions\")\n#         else:\n#             no_improve += 1\n#             if no_improve >= patience:\n#                 print(f\"No improvement for {patience} epochs. Early stopping.\")\n#                 break\n    \n#     # Load best model\n#     model.load_state_dict(torch.load(os.path.join(out_dir, f\"best_model_region_{region_id}.pth\")))\n#     print(f\"Region {region_id} training complete. Best MAE: {best_mae:.4f}\")\n    \n#     return model, best_mae, best_predictions\n\n# Function to train a single region model with improved performance\ndef train_region_model(region_id, train_ds, val_ds, backbone='efficientnet_b0', epochs=150, patience=20):\n    print(f\"\\n{'='*50}\")\n    print(f\"Training model for Region {region_id}\")\n    print(f\"{'='*50}\")\n    \n    # Get indices for this region\n    train_indices = get_region_indices(train_ds, region_id)\n    val_indices = get_region_indices(val_ds, region_id)\n    \n    print(f\"Region {region_id} has {len(train_indices)} training samples and {len(val_indices)} validation samples\")\n    \n    if len(train_indices) == 0 or len(val_indices) == 0:\n        print(f\"Skipping Region {region_id} due to insufficient data\")\n        return None, float('inf'), None\n    \n    # Create region-specific datasets\n    region_train_ds = Subset(train_ds, train_indices)\n    region_val_ds = Subset(val_ds, val_indices)\n    \n    # Create data loaders - smaller batch size for better generalization\n    batch_size = min(32, len(region_train_ds))  # Reduced from 64 to 32\n    train_loader = DataLoader(region_train_ds, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n    val_loader = DataLoader(region_val_ds, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n    \n    # Try a different, more powerful backbone for region 1\n    if region_id == 1:\n        current_backbone = 'convnext_tiny'  # Use ConvNext for region 1\n    else:\n        current_backbone = backbone\n        \n    print(f\"Using {current_backbone} backbone for region {region_id}\")\n    \n    # Initialize model with the selected backbone\n    model = MultimodalAnglePredictor(backbone=current_backbone)\n    model.to(device)\n    \n    # Initialize optimizer with different learning rate and weight decay settings\n    # Lower learning rate and stronger regularization\n    if region_id == 1:\n        opt = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.02)  \n        # Use a different scheduler for region 1\n        total_steps = epochs * len(train_loader)\n        sched = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n            opt, T_0=10, T_mult=2, eta_min=1e-6\n        )\n    else:\n        opt = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.01)\n        sched = OneCycleLR(opt, max_lr=1e-3, epochs=epochs, steps_per_epoch=len(train_loader))\n    \n    # Loss functions - weighted combination for region 1\n    crit = CircularMSELoss()\n    mae_crit = CircularMAELoss()\n    \n    # Training loop with early stopping\n    best_mae = float('inf')\n    best_epoch = 0\n    best_predictions = None\n    no_improve = 0\n    out_dir = f\"region_{region_id}_models\"\n    os.makedirs(out_dir, exist_ok=True)\n    \n    # For region 1, implement more aggressive data augmentation\n    if region_id == 1:\n        region_train_transform = transforms.Compose([\n            transforms.Resize((256,256)),\n            transforms.RandomHorizontalFlip(p=0.5),\n            transforms.RandomVerticalFlip(p=0.1),  # Additional augmentation\n            transforms.RandomRotation(20),  # More rotation\n            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),  # Additional transform\n            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Stronger color jitter\n            transforms.ToTensor(),\n            transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n            transforms.RandomErasing(p=0.2)  # Random erasing for robustness\n        ])\n        \n        # Apply the custom transform to the training dataset\n        for i in range(len(region_train_ds)):\n            region_train_ds.dataset.transform = region_train_transform\n    \n    for ep in range(epochs):\n        # Training\n        model.train()\n        running_loss = 0.0\n        running_mae = 0.0\n        \n        # Learning rate warmup for first few epochs for region 1\n        if region_id == 1 and ep < 5 and isinstance(sched, torch.optim.lr_scheduler.CosineAnnealingWarmRestarts):\n            for param_group in opt.param_groups:\n                param_group['lr'] = (ep + 1) * 5e-4 / 5\n        \n        for imgs, metas, sincos, angles, _ in tqdm(train_loader, desc=f\"Train Epoch {ep+1}/{epochs}\"):\n            imgs, metas, sincos = imgs.to(device), metas.to(device), sincos.to(device)\n            \n            opt.zero_grad()\n            out = model(imgs, metas)\n            \n            # Calculate losses\n            loss = crit(out, sincos)\n            mae_loss = mae_crit(out, sincos)\n            \n            # For region 1, apply a weighted combination of losses\n            if region_id == 1:\n                combined_loss = 0.7 * loss + 0.3 * mae_loss  # Combine MSE and MAE losses\n                combined_loss.backward()\n            else:\n                loss.backward()\n                \n            # Gradient clipping to prevent exploding gradients\n            if region_id == 1:\n                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n                \n            opt.step()\n            \n            # Different scheduler step timing\n            if region_id != 1 or not isinstance(sched, torch.optim.lr_scheduler.CosineAnnealingWarmRestarts):\n                sched.step()\n            \n            # Track metrics\n            running_loss += loss.item() * imgs.size(0)\n            running_mae += mae_loss.item() * imgs.size(0)\n            \n        # Step scheduler once per epoch for CosineAnnealingWarmRestarts\n        if region_id == 1 and isinstance(sched, torch.optim.lr_scheduler.CosineAnnealingWarmRestarts):\n            sched.step()\n            \n        train_loss = running_loss / len(region_train_ds)\n        train_mae = running_mae / len(region_train_ds)\n        \n        # Validation\n        model.eval()\n        running_loss = 0.0\n        true_ang, pred_ang = [], []\n        img_ids, predictions = [], []\n        \n        with torch.no_grad():\n            for imgs, metas, sincos, orig_ang, filenames in tqdm(val_loader, desc=f\"Val Epoch {ep+1}/{epochs}\"):\n                imgs, metas = imgs.to(device), metas.to(device)\n                sincos = sincos.to(device)\n                \n                out = model(imgs, metas)\n                loss = crit(out, sincos)\n                running_loss += loss.item() * imgs.size(0)\n                \n                # Convert to angles for MAE calculation\n                ps = out[:, 0].cpu().numpy()\n                pc = out[:, 1].cpu().numpy()\n                pa = sin_cos_to_angle(ps, pc)\n                \n                # Store predictions\n                for i in range(len(imgs)):\n                    img_id = extract_image_id(filenames[i])\n                    img_ids.append(img_id)\n                    predictions.append(pa[i])\n                \n                true_ang.extend(orig_ang.numpy())\n                pred_ang.extend(pa)\n        \n        # Calculate metrics\n        val_loss = running_loss / len(region_val_ds)\n        val_mae = circular_mae(np.array(true_ang), np.array(pred_ang))\n        val_score = 1.0 / (1.0 + val_mae)\n        \n        # Print current learning rate\n        current_lr = opt.param_groups[0]['lr']\n        print(f\"Epoch {ep+1}: Train Loss={train_loss:.4f}, Train MAE={train_mae:.4f}, Val Loss={val_loss:.4f}, Val MAE={val_mae:.4f}, Score={val_score:.4f}, LR={current_lr:.6f}\")\n        \n        # Save best model and predictions\n        if val_mae < best_mae:\n            best_mae = val_mae\n            best_epoch = ep + 1\n            no_improve = 0\n            # Save model\n            torch.save(model.state_dict(), os.path.join(out_dir, f\"best_model_region_{region_id}.pth\"))\n            \n            # Save predictions\n            best_predictions = pd.DataFrame({\n                'id': img_ids,\n                'angle': predictions\n            })\n            best_predictions.to_csv(os.path.join(out_dir, f\"best_predictions_region_{region_id}.csv\"), index=False)\n            print(f\"Saved new best model with MAE={best_mae:.4f} and predictions\")\n        else:\n            no_improve += 1\n            if no_improve >= patience:\n                print(f\"No improvement for {patience} epochs. Early stopping.\")\n                break\n    \n    # Load best model\n    model.load_state_dict(torch.load(os.path.join(out_dir, f\"best_model_region_{region_id}.pth\")))\n    print(f\"Region {region_id} training complete. Best MAE: {best_mae:.4f} at epoch {best_epoch}\")\n    \n    # If we're dealing with region 1, perform model ensemble as a final step\n    if region_id == 1 and best_mae > 40:  # If still struggling with region 1\n        print(\"Performing additional model ensemble for region 1...\")\n        # Train a secondary model with different architecture\n        second_model = MultimodalAnglePredictor(backbone='resnet34')\n        second_model.to(device)\n        second_opt = torch.optim.AdamW(second_model.parameters(), lr=3e-4, weight_decay=0.02)\n        \n        # Simplified training of second model (10 epochs)\n        for ep in range(10):\n            second_model.train()\n            for imgs, metas, sincos, _, _ in train_loader:\n                imgs, metas, sincos = imgs.to(device), metas.to(device), sincos.to(device)\n                second_opt.zero_grad()\n                out = second_model(imgs, metas)\n                loss = crit(out, sincos)\n                loss.backward()\n                second_opt.step()\n        \n        # Ensemble prediction\n        second_model.eval()\n        ensemble_img_ids, ensemble_predictions = [], []\n        with torch.no_grad():\n            for imgs, metas, _, _, filenames in val_loader:\n                imgs, metas = imgs.to(device), metas.to(device)\n                \n                # Predictions from both models\n                out1 = model(imgs, metas)\n                out2 = second_model(imgs, metas)\n                \n                # Ensemble outputs (average sin/cos values)\n                ps1, pc1 = out1[:, 0].cpu().numpy(), out1[:, 1].cpu().numpy()\n                ps2, pc2 = out2[:, 0].cpu().numpy(), out2[:, 1].cpu().numpy()\n                \n                # Simple average of sin/cos components\n                ps_avg = (ps1 + ps2) / 2\n                pc_avg = (pc1 + pc2) / 2\n                \n                # Convert to angles\n                pa_avg = sin_cos_to_angle(ps_avg, pc_avg)\n                \n                # Store predictions\n                for i in range(len(imgs)):\n                    img_id = extract_image_id(filenames[i])\n                    ensemble_img_ids.append(img_id)\n                    ensemble_predictions.append(pa_avg[i])\n        \n        # Evaluate ensemble\n        ensemble_predictions_df = pd.DataFrame({\n            'id': ensemble_img_ids,\n            'angle': ensemble_predictions\n        })\n        \n        # Compare with best previous predictions and save if better\n        true_angles = np.array(true_ang)\n        ensemble_mae = circular_mae(true_angles, np.array(ensemble_predictions))\n        \n        if ensemble_mae < best_mae:\n            print(f\"Ensemble model improved MAE from {best_mae:.4f} to {ensemble_mae:.4f}\")\n            best_mae = ensemble_mae\n            best_predictions = ensemble_predictions_df\n            best_predictions.to_csv(os.path.join(out_dir, f\"best_predictions_region_{region_id}_ensemble.csv\"), index=False)\n    \n    return model, best_mae, best_predictions\n# Train models for each region\nregion_models = {}\nregion_maes = {}\nregion_predictions = {}\nbackbone = 'efficientnet_b0'\nall_region_ids={1}\nfor region_id in all_region_ids:\n    model, best_mae, best_preds = train_region_model(\n        region_id=region_id,\n        train_ds=train_ds,\n        val_ds=val_ds,\n        backbone=backbone,\n        epochs=50,\n        patience=10\n    )\n    if model is not None:\n        region_models[region_id] = model\n        region_maes[region_id] = best_mae\n        region_predictions[region_id] = best_preds\n\n# Evaluate overall performance\n# Create a validation loader with all data\nfull_val_loader = DataLoader(val_ds, batch_size=128, shuffle=False, num_workers=4, pin_memory=True)\n\n# Load region predictor\nregion_predictor = RegionPredictor(\"/kaggle/input/regionpred/tensorflow2/default/1/region_pred_97_83.pth\")\n\n# Predictions using region-specific models\nall_true_angles = []\nall_pred_angles = []\nall_image_ids = []\nregion_wise_errors = {region_id: [] for region_id in all_region_ids}\n\nfor imgs, metas, _, orig_angles, filenames in tqdm(full_val_loader, desc=\"Evaluating with region-specific models\"):\n    imgs, metas = imgs.to(device), metas.to(device)\n    \n    # Get actual region IDs from metadata\n    region_ids = metas[:, 3].cpu().numpy()\n    \n    # For each sample in batch\n    for i in range(len(imgs)):\n        img = imgs[i:i+1]\n        meta = metas[i:i+1]\n        true_angle = orig_angles[i].item()\n        region_id = int(region_ids[i])\n        filename = filenames[i]\n        \n        # Extract image ID\n        img_id = extract_image_id(filename)\n        \n        # Get region-specific model\n        if region_id in region_models:\n            model = region_models[region_id]\n            model.eval()\n            \n            with torch.no_grad():\n                out = model(img, meta)\n                sin_val = out[0, 0].item()\n                cos_val = out[0, 1].item()\n                pred_angle = sin_cos_to_angle(sin_val, cos_val)\n            \n            # Calculate error\n            error = circular_distance(true_angle, pred_angle)\n            \n            # Store results\n            all_true_angles.append(true_angle)\n            all_pred_angles.append(pred_angle)\n            all_image_ids.append(img_id)\n            region_wise_errors[region_id].append(error)\n\n# Calculate overall MAE\noverall_mae = circular_mae(np.array(all_true_angles), np.array(all_pred_angles))\noverall_score = 1.0 / (1.0 + overall_mae)\n\nprint(\"\\n=== FINAL EVALUATION ===\")\nprint(f\"Overall MAE: {overall_mae:.4f}\")\nprint(f\"Overall Score: {overall_score:.4f}\")\n\n# Print region-wise MAEs\nprint(\"\\n=== REGION-WISE MAE ===\")\nfor region_id in sorted(region_wise_errors.keys()):\n    if len(region_wise_errors[region_id]) > 0:\n        region_mae = np.mean(region_wise_errors[region_id])\n        region_score = 1.0 / (1.0 + region_mae)\n        print(f\"Region {region_id}: MAE={region_mae:.4f}, Score={region_score:.4f}, Samples={len(region_wise_errors[region_id])}\")\n    else:\n        print(f\"Region {region_id}: No samples\")\n\n# Save all results\nresults_df = pd.DataFrame({\n    'id': all_image_ids,\n    'region_id': [region_id for region_id in region_wise_errors.keys() for _ in range(len(region_wise_errors[region_id]))],\n    'true_angle': all_true_angles,\n    'pred_angle': all_pred_angles,\n    'error': [error for region_errors in region_wise_errors.values() for error in region_errors]\n})\n\nresults_df.to_csv(\"region_specific_predictions.csv\", index=False)\nprint(\"Results saved to region_specific_predictions.csv\")\n\n# Create merged best predictions file\nall_best_predictions = pd.concat([df for df in region_predictions.values()])\nall_best_predictions = all_best_predictions.sort_values('id')\nall_best_predictions.to_csv(\"best_predictions.csv\", index=False)\nprint(\"Best predictions saved to best_predictions.csv\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}