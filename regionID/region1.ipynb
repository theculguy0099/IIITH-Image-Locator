{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11367955,"sourceType":"datasetVersion","datasetId":7116033},{"sourceId":346216,"sourceType":"modelInstanceVersion","modelInstanceId":289260,"modelId":310000},{"sourceId":346647,"sourceType":"modelInstanceVersion","modelInstanceId":289631,"modelId":310378}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torchvision.models as models\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport pandas as pd\nfrom tqdm.notebook import tqdm\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# ----------------------\n# 1. Define the Dataset\n# ----------------------\nclass RegionDataset(Dataset):\n    def __init__(self, dataframe, img_dir, transform=None):\n        self.df = dataframe\n        self.img_dir = img_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_path = os.path.join(self.img_dir, row['filename'])\n        image = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n        # Convert Region_ID to 0-indexed label\n        label = int(row['Region_ID']) - 1  \n        return image, label\n\n# ----------------------\n# 2. Define Transforms\n# ----------------------\ntrain_transform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n\n# ----------------------\n# 3. Load CSV and Create Datasets\n# ----------------------\n# Set file paths for both training and validation\ntrain_csv = \"/kaggle/input/smainewdataset/Phase_2_data/labels_train.csv\"\ntrain_img_dir = \"/kaggle/input/smainewdataset/Phase_2_data/images_train/images_train\"\nval_csv = \"/kaggle/input/smainewdataset/Phase_2_data/labels_val.csv\"\nval_img_dir = \"/kaggle/input/smainewdataset/Phase_2_data/images_val/images_val\"\n\n# Read CSV files\ntrain_df = pd.read_csv(train_csv)\ntrain_df['Region_ID'] = train_df['Region_ID'].astype(int)\nval_df = pd.read_csv(val_csv)\nval_df['Region_ID'] = val_df['Region_ID'].astype(int)\ndef filter_geo(df):\n    return df[(df.latitude.between(200000,230000)) & (df.longitude.between(140000,150000))].copy()\n\ntrain_df = filter_geo(train_df)\nprint(\"Train set size:\", len(train_df))\nprint(\"External validation set size:\", len(val_df))\n\n# Create dataset objects\ntrain_dataset = RegionDataset(train_df, train_img_dir, transform=train_transform)\nval_dataset = RegionDataset(val_df, val_img_dir, transform=val_transform)\n\n# Data loaders\nbatch_size = 32\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n\n# ----------------------\n# 4. Model Builder Function\n# ----------------------\ndef build_model(name='efficientnet_b0', num_classes=15, pretrained=True):\n    if name == 'efficientnet_b0':\n        model = models.efficientnet_b0(pretrained=pretrained)\n        in_feats = model.classifier[1].in_features\n        model.classifier[1] = nn.Linear(in_feats, num_classes)\n    elif name == 'resnet50':\n        model = models.resnet50(pretrained=pretrained)\n        in_feats = model.fc.in_features\n        model.fc = nn.Linear(in_feats, num_classes)\n    elif name == 'convnext_tiny':\n        model = models.convnext_tiny(pretrained=pretrained)\n        in_feats = model.classifier[2].in_features\n        model.classifier[2] = nn.Linear(in_feats, num_classes)\n    elif name == 'mobilenet_v3_large':\n        model = models.mobilenet_v3_large(pretrained=pretrained)\n        in_feats = model.classifier[3].in_features\n        model.classifier[3] = nn.Linear(in_feats, num_classes)\n    else:\n        raise ValueError(\"Unknown model name\")\n    return model\n\n# ----------------------\n# 5. Training and Validation with Prediction Saving\n# ----------------------\ndef train_validate(model, train_loader, val_loader, epochs=10, model_name='model'):\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n    model.to(device)\n    \n    best_acc = 0.0\n    for epoch in range(epochs):\n        # Training loop\n        model.train()\n        total_loss = 0.0\n        train_pbar = tqdm(train_loader, desc=f\"[Train Epoch {epoch+1}]\", leave=False)\n        for imgs, labels in train_pbar:\n            imgs, labels = imgs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(imgs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item() * imgs.size(0)\n            train_pbar.set_postfix({\"loss\": loss.item()})\n        \n        # Validation loop\n        model.eval()\n        correct = 0\n        total = 0\n        all_preds = []\n        all_image_ids = []\n        with torch.no_grad():\n            val_pbar = tqdm(val_loader, desc=f\"[Val Epoch {epoch+1}]\", leave=False)\n            for i, (imgs, labels) in enumerate(val_pbar):\n                imgs, labels = imgs.to(device), labels.to(device)\n                outputs = model(imgs)\n                preds = outputs.argmax(1)\n                \n                # Track image IDs for the validation set\n                batch_indices = list(range(i * batch_size, min((i + 1) * batch_size, len(val_dataset))))\n                all_image_ids.extend(batch_indices)\n                all_preds.extend(preds.cpu().numpy())\n                \n                correct += (preds == labels).sum().item()\n                total += labels.size(0)\n        \n        acc = correct / total\n        scheduler.step()\n        print(f\"Epoch {epoch+1}/{epochs}: Validation Accuracy: {acc:.6f}\")\n        \n        # Save model and predictions if accuracy improves\n        if acc > best_acc:\n            best_acc = acc\n            torch.save(model.state_dict(), f\"best_{model_name}.pth\")\n            print(f\"Model saved for {model_name} at epoch {epoch+1} (Acc: {acc:.6f})\")\n\n            # Save predictions to CSV\n            # Get filenames from validation dataframe\n            filenames = val_df['filename'].tolist()\n            preds_df = pd.DataFrame({\n                \"filename\": filenames[:len(all_preds)],\n                \"Region_ID\": [p + 1 for p in all_preds]  # Convert to 1-indexed\n            })\n            acc_str = f\"{acc:.4f}\".replace(\".\", \"_\")  # Filename-safe\n            preds_df.to_csv(f\"Region_prediction_{acc_str}.csv\", index=False)\n            print(f\"Predictions saved to Region_prediction_{acc_str}.csv\")\n\n    return best_acc\n\n# ----------------------\n# 6. Main: Build, Train, and Evaluate the Model\n# ----------------------\nmodel_name = 'convnext_tiny'  # Change to 'convnext_tiny', 'resnet50', etc.\nmodel = build_model(name=model_name, num_classes=15, pretrained=True)\nprint(\"Training with model:\", model_name)\n\n# Train and evaluate\nbest_accuracy = train_validate(model, train_loader, val_loader, epochs=300, model_name=model_name)\nprint(f\"Best Validation Accuracy for {model_name}: {best_accuracy:.6f}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import os\n# import torch\n# import torch.nn as nn\n# import torchvision.models as models\n# from torchvision import transforms\n# from torch.utils.data import Dataset, DataLoader\n# from PIL import Image\n# import pandas as pd\n# from tqdm.notebook import tqdm\n# from torch.optim.lr_scheduler import CosineAnnealingLR\n\n# # ----------------------\n# # 0. Device Configuration\n# # ----------------------\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# print(f\"Using device: {device}\\n\")\n\n# # ----------------------\n# # 1. Dataset Class\n# # ----------------------\n# class RegionDataset(Dataset):\n#     def __init__(self, dataframe, img_dir, transform=None):\n#         self.df = dataframe\n#         self.img_dir = img_dir\n#         self.transform = transform\n#         self.label_map = {label: idx for idx, label in enumerate(sorted(dataframe['Region_ID'].unique()))}\n\n#     def __len__(self):\n#         return len(self.df)\n\n#     def __getitem__(self, idx):\n#         row = self.df.iloc[idx]\n#         img_path = os.path.join(self.img_dir, row['filename'])\n#         image = Image.open(img_path).convert(\"RGB\")\n        \n#         if self.transform:\n#             image = self.transform(image)\n            \n#         label = self.label_map[row['Region_ID']]\n#         return image, label\n\n# # ----------------------\n# # 2. Transforms\n# # ----------------------\n# train_transform = transforms.Compose([\n#     transforms.Resize((256, 256)),\n#     transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n#     transforms.RandomHorizontalFlip(p=0.5),\n#     transforms.RandomVerticalFlip(p=0.2),\n#     transforms.RandomRotation(15),\n#     transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n#     transforms.ToTensor(),\n#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n#     transforms.RandomErasing(p=0.1, scale=(0.02, 0.1))\n# ])\n\n# val_transform = transforms.Compose([\n#     transforms.Resize((256, 256)),\n#     transforms.CenterCrop(224),\n#     transforms.ToTensor(),\n#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n# ])\n\n# # ----------------------\n# # 3. Data Loading\n# # ----------------------\n# def load_data(train_csv, val_csv, train_img_dir, val_img_dir):\n#     # Load and filter dataframes\n#     train_df = pd.read_csv(train_csv)\n#     val_df = pd.read_csv(val_csv)\n    \n#     geo_filter = lambda df: df[(df.latitude.between(200000,230000)) & \n#                                (df.longitude.between(140000,150000))]\n#     train_df = geo_filter(train_df)\n    \n#     print(f\"Train samples: {len(train_df):,}\")\n#     print(f\"Validation samples: {len(val_df):,}\\n\")\n    \n#     return (\n#         RegionDataset(train_df, train_img_dir, train_transform),\n#         RegionDataset(val_df, val_img_dir, val_transform)\n#     )\n\n# # ----------------------\n# # 4. Model Builder\n# # ----------------------\n# def build_model(model_name='convnext_tiny', num_classes=15):\n#     model_constructors = {\n#         'convnext_tiny': models.convnext_tiny,\n#         'efficientnet_b0': models.efficientnet_b0,\n#         'resnet50': models.resnet50,\n#         'mobilenet_v3_large': models.mobilenet_v3_large\n#     }\n    \n#     try:\n#         model = model_constructors[model_name](pretrained=True)\n#     except KeyError:\n#         raise ValueError(f\"Unsupported model: {model_name}\")\n\n#     # Modify classifier\n#     if 'convnext' in model_name:\n#         in_features = model.classifier[-1].in_features\n#         model.classifier[-1] = nn.Linear(in_features, num_classes)\n#     elif 'efficientnet' in model_name:\n#         in_features = model.classifier[-1].in_features\n#         model.classifier[-1] = nn.Linear(in_features, num_classes)\n#     elif 'resnet' in model_name:\n#         in_features = model.fc.in_features\n#         model.fc = nn.Linear(in_features, num_classes)\n#     elif 'mobilenet' in model_name:\n#         in_features = model.classifier[-1].in_features\n#         model.classifier[-1] = nn.Linear(in_features, num_classes)\n    \n#     return model\n\n# # ----------------------\n# # 5. Training Engine\n# # ----------------------\n# class TrainingEngine:\n#     def __init__(self, model, train_loader, val_loader, model_name):\n#         self.model = model.to(device)\n#         self.train_loader = train_loader\n#         self.val_loader = val_loader\n#         self.model_name = model_name\n#         self.criterion = nn.CrossEntropyLoss()\n#         self.current_epoch = 1\n#         self.best_acc = 0.0\n\n#         # Optimizer with differential learning rates\n#         backbone_params = []\n#         head_params = []\n#         for name, param in model.named_parameters():\n#             if any(k in name for k in ['classifier', 'fc', 'head']):\n#                 head_params.append(param)\n#             else:\n#                 backbone_params.append(param)\n                \n#         self.optimizer = torch.optim.AdamW(\n#             [\n#                 {'params': backbone_params, 'lr': 1e-5},\n#                 {'params': head_params, 'lr': 5e-5}\n#             ],\n#             weight_decay=1e-3\n#         )\n        \n#         self.scheduler = CosineAnnealingLR(self.optimizer, T_max=50, eta_min=1e-7)\n\n#     def load_checkpoint(self, checkpoint_path):\n#         if checkpoint_path and os.path.exists(checkpoint_path):\n#             print(f\"\\nLoading checkpoint: {checkpoint_path}\")\n#             ckpt = torch.load(checkpoint_path, map_location=device)\n            \n#             if isinstance(ckpt, dict) and 'model_state_dict' in ckpt:\n#                 self.model.load_state_dict(ckpt['model_state_dict'], strict=False)\n#                 self.best_acc = ckpt.get('best_acc', 0.0)\n#                 self.current_epoch = ckpt.get('epoch', self.current_epoch - 1) + 1\n                \n#                 if 'optimizer_state_dict' in ckpt:\n#                     self.optimizer.load_state_dict(ckpt['optimizer_state_dict'])\n#                 if 'scheduler_state_dict' in ckpt:\n#                     self.scheduler.load_state_dict(ckpt['scheduler_state_dict'])\n                \n#                 print(f\"Resumed from epoch {self.current_epoch} | Best acc: {self.best_acc:.4f}\")\n#             else:\n#                 self.model.load_state_dict(ckpt, strict=False)\n#                 print(\"Loaded model weights only\")\n#         else:\n#             print(\"\\nNo valid checkpoint found, starting from scratch\")\n\n#     def _train_epoch(self, epoch):\n#         self.model.train()\n#         total_loss = 0.0\n#         pbar = tqdm(self.train_loader, desc=f\"Epoch {epoch} [Train]\", leave=False)\n        \n#         for images, labels in pbar:\n#             images, labels = images.to(device), labels.to(device)\n            \n#             self.optimizer.zero_grad()\n#             outputs = self.model(images)\n#             loss = self.criterion(outputs, labels)\n#             loss.backward()\n#             torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n#             self.optimizer.step()\n            \n#             total_loss += loss.item()\n#             pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n        \n#         self.scheduler.step()\n#         return total_loss / len(self.train_loader)\n\n#     def _validate(self, epoch):\n#         self.model.eval()\n#         correct = 0\n#         total = 0\n#         all_preds = []\n#         all_labels = []\n        \n#         with torch.no_grad():\n#             pbar = tqdm(self.val_loader, desc=f\"Epoch {epoch} [Val]\", leave=False)\n#             for images, labels in pbar:\n#                 images = images.to(device)\n#                 outputs = self.model(images)\n#                 _, predicted = torch.max(outputs.data, 1)\n                \n#                 all_preds.extend(predicted.cpu().numpy())\n#                 all_labels.extend(labels.cpu().numpy())\n#                 total += labels.size(0)\n#                 correct += (predicted.cpu() == labels).sum().item()\n        \n#         acc = correct / total\n#         return acc, all_preds, all_labels\n\n#     def run(self, epochs, checkpoint_path=None):\n#         if checkpoint_path:\n#             self.load_checkpoint(checkpoint_path)\n        \n#         start_epoch = self.current_epoch\n#         for epoch in range(start_epoch, epochs + 1):\n#             train_loss = self._train_epoch(epoch)\n#             val_acc, preds, labels = self._validate(epoch)\n            \n#             print(f\"Epoch {epoch:03d} | Loss: {train_loss:.4f} | Acc: {val_acc:.4f} | LR: {self.optimizer.param_groups[0]['lr']:.2e}\")\n            \n#             # Update best model\n#             if val_acc > self.best_acc:\n#                 self.best_acc = val_acc\n#                 torch.save({\n#                     'epoch': epoch,\n#                     'model_state_dict': self.model.state_dict(),\n#                     'optimizer_state_dict': self.optimizer.state_dict(),\n#                     'scheduler_state_dict': self.scheduler.state_dict(),\n#                     'best_acc': self.best_acc\n#                 }, f\"best_{self.model_name}.pth\")\n                \n#                 # Save predictions\n#                 pd.DataFrame({\n#                     'filename': self.val_loader.dataset.df['filename'],\n#                     'true_label': labels,\n#                     'predicted': [p+1 for p in preds]\n#                 }).to_csv(f\"best_predictions_{val_acc:.4f}.csv\", index=False)\n            \n#             # Save latest checkpoint\n#             torch.save({\n#                 'epoch': epoch,\n#                 'model_state_dict': self.model.state_dict(),\n#                 'optimizer_state_dict': self.optimizer.state_dict(),\n#                 'scheduler_state_dict': self.scheduler.state_dict(),\n#                 'best_acc': self.best_acc\n#             }, \"latest_checkpoint.pth\")\n            \n#             self.current_epoch += 1\n\n#         return self.best_acc\n\n# # ----------------------\n# # 6. Main Execution\n# # ----------------------\n# if __name__ == \"__main__\":\n#     # Configuration\n#     CONFIG = {\n#         'model_name': 'convnext_tiny',\n#         'num_classes': 15,\n#         'epochs': 30,\n#         'batch_size': 128,\n#         'checkpoint_path': \"/kaggle/input/region-predict-97.83/tensorflow2/default/1/region_pred_97_83.pth\",\n#         'data_paths': {\n#             'train_csv': \"/kaggle/input/smainewdataset/Phase_2_data/labels_train.csv\",\n#             'val_csv': \"/kaggle/input/smainewdataset/Phase_2_data/labels_val.csv\",\n#             'train_img_dir': \"/kaggle/input/smainewdataset/Phase_2_data/images_train/images_train\",\n#             'val_img_dir': \"/kaggle/input/smainewdataset/Phase_2_data/images_val/images_val\"\n#         }\n#     }\n\n#     # Load data\n#     train_dataset, val_dataset = load_data(\n#         CONFIG['data_paths']['train_csv'],\n#         CONFIG['data_paths']['val_csv'],\n#         CONFIG['data_paths']['train_img_dir'],\n#         CONFIG['data_paths']['val_img_dir']\n#     )\n\n#     # Create dataloaders\n#     train_loader = DataLoader(\n#         train_dataset,\n#         batch_size=CONFIG['batch_size'],\n#         shuffle=True,\n#         num_workers=4,\n#         pin_memory=True\n#     )\n    \n#     val_loader = DataLoader(\n#         val_dataset,\n#         batch_size=CONFIG['batch_size'],\n#         shuffle=False,\n#         num_workers=4,\n#         pin_memory=True\n#     )\n\n#     # Initialize model\n#     model = build_model(\n#         model_name=CONFIG['model_name'],\n#         num_classes=CONFIG['num_classes']\n#     )\n\n#     # Create training engine\n#     engine = TrainingEngine(\n#         model=model,\n#         train_loader=train_loader,\n#         val_loader=val_loader,\n#         model_name=CONFIG['model_name']\n#     )\n\n#     # Run training\n#     final_acc = engine.run(\n#         epochs=CONFIG['epochs'],\n#         checkpoint_path=CONFIG['checkpoint_path']\n#     )\n\n#     print(f\"\\nTraining completed. Best validation accuracy: {final_acc:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}