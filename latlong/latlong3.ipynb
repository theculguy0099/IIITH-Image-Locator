{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11367955,"sourceType":"datasetVersion","datasetId":7116033},{"sourceId":370377,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":306639,"modelId":327124}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.hub as hub\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\nfrom tqdm.notebook import tqdm\n\n# === Device & AMP ===\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nscaler = torch.cuda.amp.GradScaler()\nprint(\"Using device:\", device)\n\n# === Paths ===\ntrain_csv     = \"/kaggle/input/smainewdataset/Phase_2_data/labels_train.csv\"\nval_csv       = \"/kaggle/input/smainewdataset/Phase_2_data/labels_val.csv\"\ntrain_img_dir = \"/kaggle/input/smainewdataset/Phase_2_data/images_train/images_train\"\nval_img_dir   = \"/kaggle/input/smainewdataset/Phase_2_data/images_val/images_val\"\n\n# === Load & Filter DataFrames ===\ntrain_df = pd.read_csv(train_csv)\nval_df   = pd.read_csv(val_csv)\ntrain_df = train_df[\n    train_df.latitude.between(200000, 230000) &\n    train_df.longitude.between(140000, 150000)\n].reset_index(drop=True)\nexclude_ids = {95, 145, 146, 158, 159, 160, 161}\nval_df = val_df[~val_df['filename'].apply(\n    lambda fn: int(os.path.splitext(fn)[0].split('_')[-1]) in exclude_ids\n)].reset_index(drop=True)\n\n# === Standardization stats ===\nlat_mean, lat_std = train_df.latitude.mean(), train_df.latitude.std()\nlon_mean, lon_std = train_df.longitude.mean(), train_df.longitude.std()\nstd_lat = lambda x: (x - lat_mean) / lat_std\ndenstd_lat = lambda x: x * lat_std + lat_mean\nstd_lon = lambda x: (x - lon_mean) / lon_std\ndenstd_lon = lambda x: x * lon_std + lon_mean\n\n# === Add cyclic embeddings ===\ndef add_cyclic(df):\n    df = df.copy()\n    df['lat_sin'] = np.sin(2 * np.pi * (df.latitude - train_df.latitude.min()) /\n                         (train_df.latitude.max() - train_df.latitude.min()))\n    df['lat_cos'] = np.cos(2 * np.pi * (df.latitude - train_df.latitude.min()) /\n                         (train_df.latitude.max() - train_df.latitude.min()))\n    df['lon_sin'] = np.sin(2 * np.pi * (df.longitude - train_df.longitude.min()) /\n                         (train_df.longitude.max() - train_df.longitude.min()))\n    df['lon_cos'] = np.cos(2 * np.pi * (df.longitude - train_df.longitude.min()) /\n                         (train_df.longitude.max() - train_df.longitude.min()))\n    parts = df.timestamp.str.split(':', expand=True).astype(float).fillna(0)\n    hh, mm = parts[0], parts[1]\n    hh=12\n    mm=30\n    df['minute_of_day'] = hh * 60 + mm\n    df['time_sin'] = np.sin(2 * np.pi * df.minute_of_day / 1440)\n    df['time_cos'] = np.cos(2 * np.pi * df.minute_of_day / 1440)\n    df['wd_sin'], df['wd_cos'] = 0.0, 1.0\n    df['mo_sin'], df['mo_cos'] = 0.0, 1.0\n    return df\n\ntrain_df = add_cyclic(train_df)\nval_df   = add_cyclic(val_df)\n\n# === Dataset definition ===\nMETA = ['lat_sin','lat_cos','lon_sin','lon_cos','time_sin','time_cos','wd_sin','wd_cos','mo_sin','mo_cos']\nclass GeoDataset(Dataset):\n    def __init__(self, df, img_dir, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.img_dir = img_dir\n        self.transform = transform\n    def __len__(self): return len(self.df)\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img = Image.open(os.path.join(self.img_dir, row.filename)).convert('RGB')\n        img = self.transform(img) if self.transform else transforms.ToTensor()(img)\n        meta = torch.from_numpy(row[META].to_numpy(dtype=np.float32))\n        lat = torch.tensor(std_lat(row.latitude), dtype=torch.float32)\n        lon = torch.tensor(std_lon(row.longitude), dtype=torch.float32)\n        return img, meta, lat, lon, row.filename\n\n# === Transforms & DataLoaders ===\ntrain_tf = transforms.Compose([\n    transforms.Resize((224,224)), transforms.RandAugment(),\n    transforms.RandomHorizontalFlip(), transforms.ColorJitter(0.3,0.3,0.2,0.1),\n    transforms.ToTensor(), transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n])\nval_tf = transforms.Compose([\n    transforms.Resize((224,224)), transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n])\nbs = 32\ntrain_loader = DataLoader(GeoDataset(train_df, train_img_dir, train_tf), batch_size=bs, shuffle=True, num_workers=4)\nval_loader   = DataLoader(GeoDataset(val_df,   val_img_dir,   val_tf), batch_size=bs, shuffle=False, num_workers=4)\n\n# === Load DINO V2 ViT-S/14 backbone ===\nprint(\"Loading DINO V2 ViT-S/14 backbone...\")\ndino = hub.load('facebookresearch/dinov2:main', 'dinov2_vits14', pretrained=True)\ndino.eval()\nmodules = [dino.patch_embed] + list(dino.blocks) + [dino.norm]\nembed_dim = dino.embed_dim\nprint(f\"DINO V2 embed dim: {embed_dim}\")\n\n# === FusionModel definition ===\nclass FusionModel(nn.Module):\n    def __init__(self, meta_dim=10):\n        super().__init__()\n        self.backbone = nn.Sequential(*modules)\n        self.meta_net = nn.Sequential(\n            nn.Linear(meta_dim,128), nn.BatchNorm1d(128), nn.ReLU(), nn.Dropout(0.5),\n            nn.Linear(128,64), nn.BatchNorm1d(64), nn.ReLU(), nn.Dropout(0.5)\n        )\n        self.head = nn.Sequential(\n            nn.Linear(embed_dim + 64,256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(0.5),\n            nn.Linear(256,2)\n        )\n    def forward(self, x, m):\n        feats = self.backbone(x)\n        cls_token = feats[:,0]\n        meta_feat = self.meta_net(m)\n        return self.head(torch.cat([cls_token, meta_feat], dim=1))\n\n# === Fine-tune & Save Predictions ===\ndef fine_tune_and_save(model, train_loader, val_loader, epochs=50,\n                       checkpoint_path='/kaggle/input/model_latlong_10700/tensorflow2/default/1/best_fusion_10700.pth', output_dir='outputs'):\n    os.makedirs(output_dir, exist_ok=True)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    # Load pretrained checkpoint\n    checkpoint = torch.load(checkpoint_path, map_location=device)\n    model.load_state_dict(checkpoint)\n    model.to(device)\n\n    # -- Initial evaluation on validation set --\n    model.eval()\n    preds_init, trues_init, fns_init = [], [], []\n    with torch.no_grad():\n        for imgs, meta, lat, lon, fnames in val_loader:\n            imgs, meta = imgs.to(device), meta.to(device)\n            with torch.cuda.amp.autocast():\n                out = model(imgs, meta).cpu().numpy()\n            preds_init.append(out)\n            trues_init.append(\n                np.stack([lat.numpy(), lon.numpy()], axis=1)\n            )\n            fns_init.extend(fnames)\n    preds_init = np.vstack(preds_init)\n    trues_init = np.vstack(trues_init)\n    lat_pred_i = denstd_lat(preds_init[:,0]); lon_pred_i = denstd_lon(preds_init[:,1])\n    lat_true_i = trues_init[:,0]*lat_std + lat_mean\n    lon_true_i = trues_init[:,1]*lon_std + lon_mean\n    mse_lat_i = ((lat_pred_i - lat_true_i)**2).mean()\n    mse_lon_i = ((lon_pred_i - lon_true_i)**2).mean()\n    avg_mse_i = 0.5*(mse_lat_i + mse_lon_i)\n    print(f\"Init Val MSE (before fine-tune): {avg_mse_i:.4f}\")\n    df_i = pd.DataFrame({\n        'filename': fns_init,\n        'pred_lat': lat_pred_i,\n        'pred_lon': lon_pred_i,\n        'true_lat': lat_true_i,\n        'true_lon': lon_true_i\n    })\n    init_csv = os.path.join(output_dir, f'init_predictions_{avg_mse_i:.4f}.csv')\n    df_i.to_csv(init_csv, index=False)\n    print(f\"Saved initial predictions to {init_csv}\")\n\n    # -- Fine-tuning loop --\n    criterion = nn.SmoothL1Loss()\n    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-2)\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer, max_lr=5e-4, epochs=epochs,\n        steps_per_epoch=len(train_loader), pct_start=0.1, anneal_strategy='cos'\n    )\n    scaler_ft = torch.cuda.amp.GradScaler()\n    best_mse = float('inf')\n    for ep in range(1, epochs+1):\n        model.train()\n        for imgs, meta, lat, lon, _ in train_loader:\n            imgs, meta, lat, lon = imgs.to(device), meta.to(device), lat.to(device), lon.to(device)\n            optimizer.zero_grad()\n            with torch.cuda.amp.autocast():\n                out = model(imgs, meta)\n                loss = 0.5*(criterion(out[:,0], lat) + criterion(out[:,1], lon))\n            scaler_ft.scale(loss).backward()\n            scaler_ft.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            scaler_ft.step(optimizer); scaler_ft.update()\n            scheduler.step()\n        # Validation\n        model.eval()\n        preds, trues, fns = [], [], []\n        with torch.no_grad():\n            for imgs, meta, lat, lon, fnames in val_loader:\n                imgs, meta = imgs.to(device), meta.to(device)\n                with torch.cuda.amp.autocast():\n                    out = model(imgs, meta).cpu().numpy()\n                preds.append(out)\n                trues.append(np.stack([lat.numpy(), lon.numpy()], axis=1))\n                fns.extend(fnames)\n        preds = np.vstack(preds); trues = np.vstack(trues)\n        lat_pred = denstd_lat(preds[:,0]); lon_pred = denstd_lon(preds[:,1])\n        lat_true = trues[:,0]*lat_std + lat_mean; lon_true = trues[:,1]*lon_std + lon_mean\n        mse_lat = ((lat_pred - lat_true)**2).mean(); mse_lon = ((lon_pred - lon_true)**2).mean()\n        avg_mse = 0.5*(mse_lat + mse_lon)\n        print(f\"Epoch {ep}/{epochs} - Val MSE: {avg_mse:.4f}\")\n        if avg_mse < best_mse:\n            best_mse = avg_mse\n            torch.save(model.state_dict(), os.path.join(output_dir, 'fine_tuned_best.pth'))\n\n    # -- Final evaluation & CSV export --\n    best_ckpt = torch.load(os.path.join(output_dir, 'fine_tuned_best.pth'), map_location=device)\n    model.load_state_dict(best_ckpt)\n    model.eval()\n    preds, trues, fns = [], [], []\n    with torch.no_grad():\n        for imgs, meta, lat, lon, fnames in val_loader:\n            imgs, meta = imgs.to(device), meta.to(device)\n            with torch.cuda.amp.autocast():\n                out = model(imgs, meta).cpu().numpy()\n            preds.append(out); trues.append(np.stack([lat.numpy(), lon.numpy()], axis=1)); fns.extend(fnames)\n    preds = np.vstack(preds); trues = np.vstack(trues)\n    lat_pred = denstd_lat(preds[:,0]); lon_pred = denstd_lon(preds[:,1])\n    lat_true = trues[:,0]*lat_std + lat_mean; lon_true = trues[:,1]*lon_std + lon_mean\n    mse_lat = ((lat_pred - lat_true)**2).mean(); mse_lon = ((lon_pred - lon_true)**2).mean()\n    avg_mse = 0.5*(mse_lat + mse_lon)\n    print(f\"Final Fine-tuned Val MSE: {avg_mse:.4f}\")\n    df = pd.DataFrame({\n        'filename': fns,\n        'pred_lat': lat_pred,\n        'pred_lon': lon_pred,\n        'true_lat': lat_true,\n        'true_lon': lon_true\n    })\n    csv_path = os.path.join(output_dir, f'predictions_{avg_mse:.4f}.csv')\n    df.to_csv(csv_path, index=False)\n    print(f\"Saved predictions to {csv_path}\")\n\n# === Run fine-tuning ===\nif __name__ == '__main__':\n    model = FusionModel(meta_dim=len(META))\n    fine_tune_and_save(model, train_loader, val_loader, epochs=200)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ### import os\n# import torch\n# import torch.nn as nn\n# import torch.hub as hub\n# from torchvision import transforms\n# from torch.utils.data import Dataset, DataLoader\n# from PIL import Image\n# import pandas as pd\n# import numpy as np\n# from tqdm.notebook import tqdm\n\n# # === Device & AMP ===\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# scaler = torch.cuda.amp.GradScaler()\n# print(\"Using device:\", device)\n\n# # === Paths ===\n# train_csv     = \"/kaggle/input/smainewdataset/Phase_2_data/labels_train.csv\"\n# val_csv       = \"/kaggle/input/smainewdataset/Phase_2_data/labels_val.csv\"\n# train_img_dir = \"/kaggle/input/smainewdataset/Phase_2_data/images_train/images_train\"\n# val_img_dir   = \"/kaggle/input/smainewdataset/Phase_2_data/images_val/images_val\"\n\n# # === Load & Filter DataFrames ===\n# train_df = pd.read_csv(train_csv)\n# val_df   = pd.read_csv(val_csv)\n\n# # Filter by coordinate range\n# train_df = train_df[\n#     train_df.latitude.between(200000, 230000) &\n#     train_df.longitude.between(140000, 150000)\n# ].reset_index(drop=True)\n# exclude_ids = {95, 145, 146, 158, 159, 160, 161}\n# val_df = val_df[~val_df['filename'].apply(\n#     lambda fn: int(os.path.splitext(fn)[0].split('_')[-1]) in exclude_ids\n# )].reset_index(drop=True)\n\n# # === Standardization stats ===\n# lat_mean, lat_std = train_df.latitude.mean(), train_df.latitude.std()\n# lon_mean, lon_std = train_df.longitude.mean(), train_df.longitude.std()\n# std_lat = lambda x: (x - lat_mean) / lat_std\n# denstd_lat = lambda x: x * lat_std + lat_mean\n# std_lon = lambda x: (x - lon_mean) / lon_std\n# denstd_lon = lambda x: x * lon_std + lon_mean\n\n# # === Add cyclic embeddings with random time placeholders ===\n# def add_cyclic(df):\n#     df = df.copy()\n#     df['lat_sin'] = np.sin(2 * np.pi * (df.latitude - train_df.latitude.min()) /\n#                          (train_df.latitude.max() - train_df.latitude.min()))\n#     df['lat_cos'] = np.cos(2 * np.pi * (df.latitude - train_df.latitude.min()) /\n#                          (train_df.latitude.max() - train_df.latitude.min()))\n#     df['lon_sin'] = np.sin(2 * np.pi * (df.longitude - train_df.longitude.min()) /\n#                          (train_df.longitude.max() - train_df.longitude.min()))\n#     df['lon_cos'] = np.cos(2 * np.pi * (df.longitude - train_df.longitude.min()) /\n#                          (train_df.longitude.max() - train_df.longitude.min()))\n#     df['time_sin'] = np.random.rand(len(df)) #because time was not given with the test set \n#     df['time_cos'] = np.random.rand(len(df))\n#     df['wd_sin'], df['wd_cos'] = 0.0, 1.0\n#     df['mo_sin'], df['mo_cos'] = 0.0, 1.0\n#     return df\n\n# train_df = add_cyclic(train_df)\n# val_df   = add_cyclic(val_df)\n\n# # === Dataset definition ===\n# META = ['lat_sin','lat_cos','lon_sin','lon_cos','time_sin','time_cos','wd_sin','wd_cos','mo_sin','mo_cos']\n# class GeoDataset(Dataset):\n#     def __init__(self, df, img_dir, transform=None):\n#         self.df = df.reset_index(drop=True)\n#         self.img_dir = img_dir\n#         self.transform = transform\n#     def __len__(self): return len(self.df)\n#     def __getitem__(self, idx):\n#         row = self.df.iloc[idx]\n#         img = Image.open(os.path.join(self.img_dir, row.filename)).convert('RGB')\n#         img = self.transform(img) if self.transform else transforms.ToTensor()(img)\n#         meta = torch.from_numpy(row[META].to_numpy(dtype=np.float32))\n#         lat = torch.tensor(std_lat(row.latitude), dtype=torch.float32)\n#         lon = torch.tensor(std_lon(row.longitude), dtype=torch.float32)\n#         return img, meta, lat, lon, row.filename\n\n# train_tf = transforms.Compose([\n#     transforms.Resize((224,224)), transforms.RandAugment(),\n#     transforms.RandomHorizontalFlip(), transforms.ColorJitter(0.3,0.3,0.2,0.1),\n#     transforms.ToTensor(), transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n# ])\n# val_tf = transforms.Compose([\n#     transforms.Resize((224,224)), transforms.ToTensor(),\n#     transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n# ])\n# bs = 32\n# train_loader = DataLoader(GeoDataset(train_df, train_img_dir, train_tf), batch_size=bs, shuffle=True, num_workers=4)\n# val_loader   = DataLoader(GeoDataset(val_df,   val_img_dir,   val_tf), batch_size=bs, shuffle=False, num_workers=4)\n\n# print(\"Loading DINO V2 ViT-S/14 backbone...\")\n# dino = hub.load('facebookresearch/dinov2:main', 'dinov2_vits14', pretrained=True)\n# dino.eval()\n# modules = [dino.patch_embed] + list(dino.blocks) + [dino.norm]\n# embed_dim = dino.embed_dim\n# print(f\"DINO V2 embed dim: {embed_dim}\")\n\n# class FusionModel(nn.Module):\n#     def __init__(self, meta_dim=len(META)):\n#         super().__init__()\n#         self.backbone = nn.Sequential(*modules)\n#         self.meta_net = nn.Sequential(\n#             nn.Linear(meta_dim,128), nn.BatchNorm1d(128), nn.ReLU(), nn.Dropout(0.5),\n#             nn.Linear(128,64), nn.BatchNorm1d(64), nn.ReLU(), nn.Dropout(0.5)\n#         )\n#         self.head = nn.Sequential(\n#             nn.Linear(embed_dim + 64,256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(0.5),\n#             nn.Linear(256,2)\n#         )\n#     def forward(self, x, m):\n#         feats = self.backbone(x)\n#         cls_token = feats[:,0]\n#         meta_feat = self.meta_net(m)\n#         return self.head(torch.cat([cls_token, meta_feat], dim=1))\n\n\n# def fine_tune_and_save(model, train_loader, val_loader, epochs=50,\n#                        checkpoint_path='/kaggle/input/model_latlong_10700/tensorflow2/default/1/best_fusion_10700.pth', output_dir='outputs'):\n#     os.makedirs(output_dir, exist_ok=True)\n#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n#     # Load pretrained checkpoint (weights only)\n#     checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=True)\n#     model.load_state_dict(checkpoint)\n#     model.to(device)\n\n#     # Initial evaluation\n#     def eval_loop(loader):\n#         preds, trues, fns = [], [], []\n#         model.eval()\n#         with torch.no_grad():\n#             for imgs, meta, lat, lon, fnames in loader:\n#                 imgs, meta = imgs.to(device), meta.to(device)\n#                 with torch.cuda.amp.autocast():\n#                     out = model(imgs, meta).cpu().numpy()\n#                 preds.append(out)\n#                 trues.append(np.stack([lat.numpy(), lon.numpy()], axis=1))\n#                 fns.extend(fnames)\n#         preds = np.vstack(preds); trues = np.vstack(trues)\n#         lat_pred = denstd_lat(preds[:,0]); lon_pred = denstd_lon(preds[:,1])\n#         lat_true = trues[:,0]*lat_std + lat_mean; lon_true = trues[:,1]*lon_std + lon_mean\n#         mse_lat = ((lat_pred - lat_true)**2).mean(); mse_lon = ((lon_pred - lon_true)**2).mean()\n#         return 0.5*(mse_lat + mse_lon), fns, lat_pred, lon_pred, lat_true, lon_true\n\n#     init_mse, fns_i, lat_p_i, lon_p_i, lat_t_i, lon_t_i = eval_loop(val_loader)\n#     print(f\"Init Val MSE: {init_mse:.4f}\")\n#     pd.DataFrame({'filename':fns_i,'pred_lat':lat_p_i,'pred_lon':lon_p_i,'true_lat':lat_t_i,'true_lon':lon_t_i})\\\n#        .to_csv(os.path.join(output_dir, f'init_predictions_{init_mse:.4f}.csv'), index=False)\n\n#     # Training\n#     criterion = nn.SmoothL1Loss()\n#     optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-2)\n#     scheduler = torch.optim.lr_scheduler.OneCycleLR(\n#         optimizer, max_lr=5e-4, epochs=epochs,\n#         steps_per_epoch=len(train_loader), pct_start=0.1, anneal_strategy='cos'\n#     )\n#     scaler_ft = torch.cuda.amp.GradScaler()\n#     best_mse = float('inf')\n\n#     for ep in range(1, epochs+1):\n#         model.train()\n#         for imgs, meta, lat, lon, _ in train_loader:\n#             imgs, meta, lat, lon = imgs.to(device), meta.to(device), lat.to(device), lon.to(device)\n#             optimizer.zero_grad()\n#             with torch.cuda.amp.autocast():\n#                 out = model(imgs, meta)\n#                 loss = 0.5*(criterion(out[:,0], lat) + criterion(out[:,1], lon))\n#             scaler_ft.scale(loss).backward()\n#             scaler_ft.unscale_(optimizer)\n#             torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n#             scaler_ft.step(optimizer)\n#             scaler_ft.update()\n#             scheduler.step()\n\n#         val_mse, _, _, _, _, _ = eval_loop(val_loader)\n#         print(f\"Epoch {ep}/{epochs} Val MSE: {val_mse:.4f}\")\n#         if val_mse < best_mse:\n#             best_mse = val_mse\n#             torch.save(model.state_dict(), os.path.join(output_dir, 'fine_tuned_best.pth'))\n\n#     # Final eval\n#     model.load_state_dict(torch.load(os.path.join(output_dir, 'fine_tuned_best.pth'), map_location=device, weights_only=True))\n#     final_mse, fns_f, lat_p_f, lon_p_f, lat_t_f, lon_t_f = eval_loop(val_loader)\n#     print(f\"Final Val MSE: {final_mse:.4f}\")\n#     pd.DataFrame({'filename':fns_f,'pred_lat':lat_p_f,'pred_lon':lon_p_f,'true_lat':lat_t_f,'true_lon':lon_t_f})\\\n#        .to_csv(os.path.join(output_dir, f'predictions_{final_mse:.4f}.csv'), index=False)\n\n# if __name__ == '__main__':\n#     model = FusionModel()\n#     fine_tune_and_save(model, train_loader, val_loader, epochs=200)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}